# AI Agent Evaluations

## AI Agent Evaluations

**Systematic evaluation of AI agent quality, reliability, and safety to ensure production readiness and continuous improvement**

AI agent evaluations (evals) are critical for maintaining high-quality automated workflows. This guide shows how to build robust evaluation systems using ALOMA's conditional execution model to continuously assess and improve your AI agents.

***

### Overview

#### What are AI Agent Evals?

**Evaluations** are systematic processes for measuring and assessing the quality, reliability, and safety of AI systems to determine if they meet business goals and operate within acceptable parameters.

In ALOMA, evals are implemented as **conditional steps** that validate agent outputs, measure performance metrics, and trigger improvement workflowsâ€”enabling continuous quality assurance throughout the agent lifecycle.

#### Why Evals Matter

**Quality Assurance**: Catch errors before they impact business operations or customers

**Continuous Improvement**: Identify patterns and opportunities for agent optimization

**Risk Management**: Detect safety issues, hallucinations, or policy violations early

**Cost Optimization**: Monitor token usage and identify efficiency opportunities

**Business Confidence**: Provide measurable metrics that justify AI investment

#### When to Implement Evals

**Immediately** (Basic Evals):

* Output format validation
* Required field presence checks
* Basic safety guardrails

**After Initial Deployment** (Advanced Evals):

* Quality scoring and accuracy measurement
* Cost optimization analysis
* A/B testing and comparison
* Learning system integration

***

### Evaluation Framework

#### Types of Evaluations

**1. Functional Evals**

Validate that agents complete their intended tasks correctly:

```javascript
// Functional Eval: Verify Agent Task Completion
export const condition = {
  agentOutput: {
    classification: Object,
    taskComplete: true
  },
  functionalEval: null
};

export const content = async () => {
  console.log('Running functional evaluation on agent output...');
  
  const output = data.agentOutput;
  const evalResults = {
    taskCompletionValid: false,
    requiredFieldsPresent: false,
    outputFormatValid: false,
    errors: []
  };
  
  // 1. Check task completion validity
  if (output.taskComplete === true && output.classification) {
    evalResults.taskCompletionValid = true;
  } else {
    evalResults.errors.push('Task marked complete but missing classification');
  }
  
  // 2. Verify required fields
  const requiredFields = ['category', 'confidence', 'reasoning'];
  const missingFields = requiredFields.filter(field => !output.classification[field]);
  
  if (missingFields.length === 0) {
    evalResults.requiredFieldsPresent = true;
  } else {
    evalResults.errors.push(`Missing required fields: ${missingFields.join(', ')}`);
  }
  
  // 3. Validate output format
  if (typeof output.classification.confidence === 'number' &&
      output.classification.confidence >= 0 && 
      output.classification.confidence <= 100) {
    evalResults.outputFormatValid = true;
  } else {
    evalResults.errors.push('Confidence must be number between 0-100');
  }
  
  // Calculate overall pass/fail
  evalResults.passed = evalResults.taskCompletionValid && 
                        evalResults.requiredFieldsPresent && 
                        evalResults.outputFormatValid;
  evalResults.evaluatedAt = new Date().toISOString();
  
  data.functionalEval = evalResults;
  
  console.log(`Functional eval: ${evalResults.passed ? 'PASSED' : 'FAILED'} - ${evalResults.errors.length} errors`);
};
```

**2. Quality Evals**

Assess the quality and accuracy of agent outputs:

```javascript
// Quality Eval: LLM-as-Judge Pattern
export const condition = {
  agentOutput: {
    researchSummary: String,
    sources: Array
  },
  functionalEval: { passed: true },
  qualityEval: null
};

export const content = async () => {
  console.log('Running quality evaluation on agent research output...');
  
  // Use Claude/GPT as judge to evaluate quality
  const qualityAssessment = await connectors.openai.chat({
    model: 'gpt-4',
    messages: [
      {
        role: 'system',
        content: `You are an expert evaluator assessing research quality. Evaluate the following criteria:

1. **Relevance** (0-10): How relevant is the summary to the original query?
2. **Accuracy** (0-10): Are facts accurate and properly sourced?
3. **Completeness** (0-10): Does it cover all key aspects?
4. **Clarity** (0-10): Is it well-written and easy to understand?
5. **Source Quality** (0-10): Are sources credible and diverse?

Provide scores and specific reasoning for each criterion. Return JSON only:
{
  "scores": {
    "relevance": number,
    "accuracy": number,
    "completeness": number,
    "clarity": number,
    "sourceQuality": number
  },
  "overallScore": number,
  "strengths": ["strength1", "strength2"],
  "weaknesses": ["weakness1", "weakness2"],
  "improvementSuggestions": ["suggestion1", "suggestion2"]
}`
      },
      {
        role: 'user',
        content: `Original Query: ${data.agentInput.query}

Agent Research Summary:
${data.agentOutput.researchSummary}

Sources Used:
${JSON.stringify(data.agentOutput.sources, null, 2)}

Evaluate this research output.`
      }
    ]
  });
  
  const assessment = JSON.parse(qualityAssessment.choices[0].message.content);
  
  // Calculate pass/fail based on thresholds
  const averageScore = assessment.overallScore;
  const qualityThreshold = 7.0; // Configurable threshold
  
  data.qualityEval = {
    passed: averageScore >= qualityThreshold,
    scores: assessment.scores,
    overallScore: averageScore,
    threshold: qualityThreshold,
    strengths: assessment.strengths,
    weaknesses: assessment.weaknesses,
    improvementSuggestions: assessment.improvementSuggestions,
    evaluatedAt: new Date().toISOString(),
    evaluatorModel: 'gpt-4'
  };
  
  console.log(`Quality eval: ${data.qualityEval.passed ? 'PASSED' : 'FAILED'} - Score: ${averageScore}/${qualityThreshold}`);
};
```

**3. Safety Evals**

Detect potential safety issues, policy violations, or harmful outputs:

```javascript
// Safety Eval: Content Safety and PII Detection
export const condition = {
  agentOutput: {
    customerResponse: String
  },
  qualityEval: { passed: true },
  safetyEval: null
};

export const content = async () => {
  console.log('Running safety evaluation on agent output...');
  
  const response = data.agentOutput.customerResponse;
  const safetyResults = {
    piiDetected: false,
    piiFindings: [],
    harmfulContent: false,
    harmfulCategories: [],
    promptInjection: false,
    confidentialDataLeaked: false,
    errors: []
  };
  
  // 1. PII Detection (deterministic checks)
  const piiPatterns = {
    email: /[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/g,
    phone: /(\+\d{1,3}[\s-])?\(?\d{3}\)?[\s.-]?\d{3}[\s.-]?\d{4}/g,
    ssn: /\d{3}-\d{2}-\d{4}/g,
    creditCard: /\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}/g
  };
  
  for (const [type, pattern] of Object.entries(piiPatterns)) {
    const matches = response.match(pattern);
    if (matches && matches.length > 0) {
      safetyResults.piiDetected = true;
      safetyResults.piiFindings.push({
        type: type,
        count: matches.length,
        examples: matches.slice(0, 2) // Show first 2 examples only
      });
    }
  }
  
  // 2. Content Safety Check (using LLM)
  const safetyCheck = await connectors.openai.chat({
    model: 'gpt-4',
    messages: [
      {
        role: 'system',
        content: `You are a content safety evaluator. Analyze if this text contains:
1. Harmful, offensive, or inappropriate content
2. Potential prompt injection attempts
3. Confidential business information or trade secrets
4. Misleading or false information

Return JSON only:
{
  "isHarmful": boolean,
  "harmfulCategories": ["category1", "category2"],
  "hasPromptInjection": boolean,
  "hasConfidentialData": boolean,
  "explanation": "brief explanation"
}`
      },
      {
        role: 'user',
        content: response
      }
    ]
  });
  
  const safetyAnalysis = JSON.parse(safetyCheck.choices[0].message.content);
  
  safetyResults.harmfulContent = safetyAnalysis.isHarmful;
  safetyResults.harmfulCategories = safetyAnalysis.harmfulCategories || [];
  safetyResults.promptInjection = safetyAnalysis.hasPromptInjection;
  safetyResults.confidentialDataLeaked = safetyAnalysis.hasConfidentialData;
  
  // Calculate overall safety pass/fail
  safetyResults.passed = !safetyResults.piiDetected && 
                         !safetyResults.harmfulContent && 
                         !safetyResults.promptInjection &&
                         !safetyResults.confidentialDataLeaked;
  
  if (!safetyResults.passed) {
    safetyResults.errors.push(safetyAnalysis.explanation);
  }
  
  safetyResults.evaluatedAt = new Date().toISOString();
  
  data.safetyEval = safetyResults;
  
  console.log(`Safety eval: ${safetyResults.passed ? 'PASSED' : 'FAILED'} - ${safetyResults.errors.length} issues found`);
};
```

**4. Performance Evals**

Monitor efficiency, speed, and cost metrics:

```javascript
// Performance Eval: Cost and Efficiency Monitoring
export const condition = {
  agentExecution: {
    completed: true,
    startTime: String,
    endTime: String
  },
  agentOutput: Object,
  safetyEval: { passed: true },
  performanceEval: null
};

export const content = async () => {
  console.log('Running performance evaluation on agent execution...');
  
  const execution = data.agentExecution;
  const output = data.agentOutput;
  
  // Calculate execution time
  const startTime = new Date(execution.startTime);
  const endTime = new Date(execution.endTime);
  const executionTimeMs = endTime - startTime;
  const executionTimeSec = executionTimeMs / 1000;
  
  // Estimate token usage and cost
  const estimatedInputTokens = execution.inputTokens || 0;
  const estimatedOutputTokens = execution.outputTokens || 0;
  const totalTokens = estimatedInputTokens + estimatedOutputTokens;
  
  // Cost calculation (example rates for GPT-4)
  const inputCostPer1k = 0.03; // $0.03 per 1K input tokens
  const outputCostPer1k = 0.06; // $0.06 per 1K output tokens
  const estimatedCost = (estimatedInputTokens / 1000 * inputCostPer1k) + 
                        (estimatedOutputTokens / 1000 * outputCostPer1k);
  
  // Define performance thresholds
  const maxExecutionTimeSec = 30; // 30 seconds
  const maxCostPerExecution = 0.50; // $0.50
  const maxTokensPerExecution = 10000; // 10K tokens
  
  // Evaluate performance
  const performanceResults = {
    executionTime: {
      seconds: executionTimeSec,
      milliseconds: executionTimeMs,
      withinThreshold: executionTimeSec <= maxExecutionTimeSec,
      threshold: maxExecutionTimeSec
    },
    tokenUsage: {
      input: estimatedInputTokens,
      output: estimatedOutputTokens,
      total: totalTokens,
      withinThreshold: totalTokens <= maxTokensPerExecution,
      threshold: maxTokensPerExecution
    },
    cost: {
      estimated: estimatedCost,
      withinThreshold: estimatedCost <= maxCostPerExecution,
      threshold: maxCostPerExecution,
      currency: 'USD'
    },
    efficiency: {
      tokensPerSecond: totalTokens / executionTimeSec,
      costPerSecond: estimatedCost / executionTimeSec
    }
  };
  
  // Overall performance pass
  performanceResults.passed = performanceResults.executionTime.withinThreshold &&
                               performanceResults.tokenUsage.withinThreshold &&
                               performanceResults.cost.withinThreshold;
  
  // Add warnings if approaching thresholds
  performanceResults.warnings = [];
  if (executionTimeSec > maxExecutionTimeSec * 0.8) {
    performanceResults.warnings.push('Execution time approaching threshold');
  }
  if (estimatedCost > maxCostPerExecution * 0.8) {
    performanceResults.warnings.push('Cost approaching threshold');
  }
  
  performanceResults.evaluatedAt = new Date().toISOString();
  
  data.performanceEval = performanceResults;
  
  console.log(`Performance eval: ${performanceResults.passed ? 'PASSED' : 'FAILED'} - Time: ${executionTimeSec}s, Cost: $${estimatedCost.toFixed(4)}`);
};
```

***

### Implementation Patterns

#### Pattern 1: Inline Evaluation Steps

Add evaluation steps immediately after agent execution for real-time validation:

```javascript
// Step 1: Agent Execution
export const condition = {
  support: {
    ticket: Object,
    agentProcessing: null
  }
};

export const content = async () => {
  console.log('Agent processing support ticket...');
  
  const startTime = new Date();
  
  const classification = await connectors.openai.chat({
    model: 'gpt-4',
    messages: [{
      role: 'system',
      content: 'Classify this support ticket by category, urgency, and sentiment.'
    }, {
      role: 'user',
      content: data.support.ticket.message
    }]
  });
  
  const result = JSON.parse(classification.choices[0].message.content);
  
  data.agentOutput = {
    classification: result,
    taskComplete: true
  };
  
  data.agentExecution = {
    completed: true,
    startTime: startTime.toISOString(),
    endTime: new Date().toISOString(),
    inputTokens: classification.usage.prompt_tokens,
    outputTokens: classification.usage.completion_tokens
  };
  
  data.agentProcessing = true;
};

// Step 2: Immediate Eval (runs automatically after agent)
export const condition = {
  agentOutput: {
    classification: Object,
    taskComplete: true
  },
  agentEval: null
};

export const content = async () => {
  console.log('Evaluating agent output...');
  
  const output = data.agentOutput.classification;
  const evalResult = {
    passed: false,
    errors: []
  };
  
  // Validation checks
  const requiredFields = ['category', 'urgency', 'sentiment', 'confidence'];
  const missingFields = requiredFields.filter(f => !output[f]);
  
  if (missingFields.length > 0) {
    evalResult.errors.push(`Missing fields: ${missingFields.join(', ')}`);
  }
  
  if (output.confidence < 70) {
    evalResult.errors.push('Confidence below acceptable threshold (70)');
  }
  
  evalResult.passed = evalResult.errors.length === 0;
  
  data.agentEval = evalResult;
  
  console.log(`Agent eval: ${evalResult.passed ? 'PASSED' : 'FAILED'}`);
};

// Step 3: Handle Eval Failures
export const condition = {
  agentEval: {
    passed: false
  },
  evalFailureHandled: null
};

export const content = async () => {
  console.log('Handling agent evaluation failure...');
  
  // Option 1: Retry with different parameters
  if (data.agentOutput.classification.confidence < 50) {
    console.log('Low confidence - triggering retry with enhanced prompt');
    data.support.agentProcessing = null; // Reset to retry
    data.support.retryAttempt = (data.support.retryAttempt || 0) + 1;
    data.support.useEnhancedPrompt = true;
  }
  
  // Option 2: Flag for human review
  else {
    console.log('Flagging for human review');
    
    await connectors.slack.send({
      channel: '#support-review',
      text: `âš ï¸ Agent evaluation failed for ticket ${data.support.ticket.id}\nErrors: ${data.agentEval.errors.join(', ')}`
    });
    
    data.support.requiresHumanReview = true;
    data.support.escalated = true;
  }
  
  data.evalFailureHandled = true;
};
```

#### Pattern 2: Batch Evaluation Workflows

Periodically evaluate completed tasks to assess overall agent performance:

```javascript
// Batch Eval Trigger: Daily Performance Review
export const condition = {
  batchEval: {
    trigger: 'daily_review',
    date: String
  },
  tasksSampled: null
};

export const content = async () => {
  console.log(`Starting daily batch evaluation for ${data.batchEval.date}...`);
  
  // Sample completed tasks from the past day
  const samplingStrategy = {
    totalTasks: 1000, // Example: 1000 tasks completed today
    sampleSize: 100, // Evaluate 100 randomly sampled tasks
    samplingMethod: 'stratified' // Ensure representative sample
  };
  
  // In practice, you would query completed tasks from your data store
  // For this example, we'll create a sample structure
  data.evalSample = {
    date: data.batchEval.date,
    totalTasks: samplingStrategy.totalTasks,
    sampleSize: samplingStrategy.sampleSize,
    sampledTaskIds: [], // Would contain actual task IDs
    evaluationsPending: samplingStrategy.sampleSize
  };
  
  data.tasksSampled = true;
  
  console.log(`Sampled ${samplingStrategy.sampleSize} tasks for evaluation`);
};

// Create Eval Subtasks for Each Sampled Task
export const condition = {
  evalSample: {
    sampledTaskIds: Array,
    evaluationsPending: Number
  },
  evalSubtasksCreated: null
};

export const content = async () => {
  console.log(`Creating evaluation subtasks for ${data.evalSample.sampleSize} sampled tasks...`);
  
  // Create a subtask for each sampled task to run evaluation
  data.evalSample.sampledTaskIds.forEach((taskId, index) => {
    task.subtask(
      `Eval task ${taskId}`,
      {
        evalTask: {
          originalTaskId: taskId,
          sampleIndex: index,
          runTaskEval: true
        }
      },
      {
        into: `evalResults.${index}`,
        waitFor: false // Run in parallel
      }
    );
  });
  
  data.evalSubtasksCreated = true;
  
  console.log(`Created ${data.evalSample.sampledTaskIds.length} evaluation subtasks`);
};

// Aggregate Batch Eval Results
export const condition = {
  evalSample: Object,
  evalSubtasksCreated: true,
  evalResults: Array,
  aggregatedResults: null
};

export const content = async () => {
  console.log('Aggregating batch evaluation results...');
  
  const results = data.evalResults;
  
  // Calculate aggregate metrics
  const aggregation = {
    totalEvaluated: results.length,
    passRate: results.filter(r => r.passed).length / results.length * 100,
    avgQualityScore: results.reduce((sum, r) => sum + (r.qualityScore || 0), 0) / results.length,
    commonErrors: {},
    performanceMetrics: {
      avgExecutionTime: results.reduce((sum, r) => sum + (r.executionTime || 0), 0) / results.length,
      avgCost: results.reduce((sum, r) => sum + (r.cost || 0), 0) / results.length
    }
  };
  
  // Identify common error patterns
  results.forEach(result => {
    if (!result.passed && result.errors) {
      result.errors.forEach(error => {
        aggregation.commonErrors[error] = (aggregation.commonErrors[error] || 0) + 1;
      });
    }
  });
  
  // Determine if performance meets thresholds
  const passRateThreshold = 95; // 95% pass rate required
  const qualityScoreThreshold = 8.0; // Quality score of 8.0+ required
  
  aggregation.meetsStandards = aggregation.passRate >= passRateThreshold &&
                                aggregation.avgQualityScore >= qualityScoreThreshold;
  
  data.aggregatedResults = aggregation;
  data.batchEvalComplete = true;
  
  console.log(`Batch eval complete: ${aggregation.passRate.toFixed(1)}% pass rate, ${aggregation.avgQualityScore.toFixed(2)} avg quality`);
};

// Alert on Quality Degradation
export const condition = {
  aggregatedResults: {
    meetsStandards: false
  },
  qualityAlert: null
};

export const content = async () => {
  console.log('âš ï¸ Agent quality degradation detected - sending alerts...');
  
  const results = data.aggregatedResults;
  
  // Create detailed alert
  const alertMessage = `
ðŸš¨ AI Agent Quality Alert - ${data.batchEval.date}

**Performance Summary:**
- Pass Rate: ${results.passRate.toFixed(1)}% (threshold: 95%)
- Avg Quality Score: ${results.avgQualityScore.toFixed(2)} (threshold: 8.0)
- Total Tasks Evaluated: ${results.totalEvaluated}

**Common Errors:**
${Object.entries(results.commonErrors)
  .sort((a, b) => b[1] - a[1])
  .slice(0, 5)
  .map(([error, count]) => `- ${error}: ${count} occurrences`)
  .join('\n')}

**Action Required:** Review agent configuration and prompts
  `;
  
  // Send alerts via multiple channels
  await connectors.slack.send({
    channel: '#ai-monitoring',
    text: alertMessage
  });
  
  await connectors.email.send({
    to: 'ai-team@company.com',
    subject: `âš ï¸ AI Agent Quality Alert - ${data.batchEval.date}`,
    body: alertMessage
  });
  
  data.qualityAlert = {
    sent: true,
    timestamp: new Date().toISOString(),
    severity: 'high',
    results: results
  };
};
```

#### Pattern 3: Human-in-the-Loop Evaluation

Route uncertain or complex cases to human reviewers:

```javascript
// Agent Confidence Check
export const condition = {
  agentOutput: {
    classification: Object,
    taskComplete: true
  },
  confidenceCheck: null
};

export const content = async () => {
  const confidence = data.agentOutput.classification.confidence;
  const uncertaintyThreshold = 80; // Confidence below 80% triggers review
  
  data.confidenceCheck = {
    confidence: confidence,
    requiresHumanReview: confidence < uncertaintyThreshold,
    threshold: uncertaintyThreshold,
    checkedAt: new Date().toISOString()
  };
  
  console.log(`Confidence check: ${confidence}% - ${data.confidenceCheck.requiresHumanReview ? 'HUMAN REVIEW REQUIRED' : 'OK'}`);
};

// Create Human Review Queue
export const condition = {
  confidenceCheck: {
    requiresHumanReview: true
  },
  humanReviewQueued: null
};

export const content = async () => {
  console.log('Creating human review task for low-confidence output...');
  
  // Create review entry
  const reviewTask = {
    taskId: task.id,
    reviewType: 'low_confidence_classification',
    agentOutput: data.agentOutput.classification,
    confidence: data.confidenceCheck.confidence,
    originalInput: data.support.ticket.message,
    priority: data.confidenceCheck.confidence < 50 ? 'high' : 'normal',
    assignedTo: null,
    createdAt: new Date().toISOString()
  };
  
  // Send to review system (could be database, Slack, etc.)
  await connectors.reviewQueue.create(reviewTask);
  
  // Notify human reviewers
  await connectors.slack.send({
    channel: '#human-review',
    text: `ðŸ” New review task: ${reviewTask.reviewType}\nConfidence: ${reviewTask.confidence}%\nPriority: ${reviewTask.priority}\nTask ID: ${task.id}`,
    blocks: [
      {
        type: 'section',
        text: {
          type: 'mrkdwn',
          text: `*Review Required*\n\n*Type:* ${reviewTask.reviewType}\n*Confidence:* ${reviewTask.confidence}%\n*Priority:* ${reviewTask.priority}`
        }
      },
      {
        type: 'actions',
        elements: [
          {
            type: 'button',
            text: { type: 'plain_text', text: 'Review Now' },
            url: `https://review.company.com/tasks/${task.id}`
          }
        ]
      }
    ]
  });
  
  data.humanReviewQueued = true;
  data.support.awaitingHumanReview = true;
};

// Process Human Feedback
export const condition = {
  humanReview: {
    completed: true,
    feedback: Object
  },
  feedbackProcessed: null
};

export const content = async () => {
  console.log('Processing human reviewer feedback...');
  
  const feedback = data.humanReview.feedback;
  const agentOutput = data.agentOutput.classification;
  
  // Compare agent output with human judgment
  const comparison = {
    agentCategory: agentOutput.category,
    humanCategory: feedback.correctCategory,
    agentUrgency: agentOutput.urgency,
    humanUrgency: feedback.correctUrgency,
    agreement: agentOutput.category === feedback.correctCategory &&
               agentOutput.urgency === feedback.correctUrgency
  };
  
  // Store for learning
  data.evalLearning = {
    comparison: comparison,
    agentConfidence: data.confidenceCheck.confidence,
    humanCorrection: !comparison.agreement,
    feedbackNotes: feedback.notes,
    reviewedAt: new Date().toISOString(),
    reviewedBy: feedback.reviewerId
  };
  
  // If human corrected the output, update the classification
  if (!comparison.agreement) {
    data.agentOutput.classification.category = feedback.correctCategory;
    data.agentOutput.classification.urgency = feedback.correctUrgency;
    data.agentOutput.classification.humanCorrected = true;
  }
  
  data.feedbackProcessed = true;
  
  console.log(`Human feedback processed - Agreement: ${comparison.agreement}`);
};
```

***

### Evaluation Metrics & Monitoring

#### Defining Success Metrics

Establish clear, measurable criteria for agent performance:

```javascript
// Metrics Aggregation Step
export const condition = {
  metricsAggregation: {
    trigger: 'weekly_report',
    dateRange: Object
  },
  metricsCalculated: null
};

export const content = async () => {
  console.log(`Calculating agent metrics for ${data.metricsAggregation.dateRange.start} to ${data.metricsAggregation.dateRange.end}...`);
  
  // In production, query from your data store
  // This example shows the metric structure
  const metrics = {
    volume: {
      totalTasks: 5000,
      tasksEvaluated: 500,
      evaluationRate: 0.10 // 10% sampling
    },
    
    quality: {
      passRate: 96.5, // % of evals that passed
      avgQualityScore: 8.3, // Average quality score (0-10)
      humanAgreementRate: 94.2 // % agreement with human reviewers
    },
    
    performance: {
      avgExecutionTime: 12.5, // seconds
      avgCost: 0.08, // USD per task
      totalCost: 400.00, // Total cost for period
      tokenEfficiency: 750 // avg tokens per task
    },
    
    safety: {
      piiDetectionRate: 0.2, // % of tasks with PII detected
      safetyViolations: 3, // Count of safety issues
      promptInjectionAttempts: 1
    },
    
    errors: {
      totalErrors: 45,
      errorRate: 0.9, // % of tasks with errors
      commonErrorTypes: {
        'missing_required_field': 18,
        'low_confidence': 15,
        'format_validation_failed': 12
      }
    },
    
    improvements: {
      weekOverWeekQualityChange: +2.1, // % improvement
      weekOverWeekCostChange: -5.3, // % reduction
      weekOverWeekSpeedChange: -8.2 // % faster
    }
  };
  
  data.agentMetrics = {
    period: data.metricsAggregation.dateRange,
    metrics: metrics,
    calculatedAt: new Date().toISOString()
  };
  
  data.metricsCalculated = true;
  
  console.log(`Metrics calculated - Pass rate: ${metrics.quality.passRate}%, Avg cost: ${metrics.performance.avgCost}`);
};
```

#### Tracking Eval Results

Store evaluation results in task metadata for querying and analysis:

```javascript
// Store Eval Results in Task Metadata
export const condition = {
  functionalEval: Object,
  qualityEval: Object,
  safetyEval: Object,
  performanceEval: Object,
  evalResultsStored: null
};

export const content = async () => {
  console.log('Storing evaluation results for analysis...');
  
  // Aggregate all eval results
  const consolidatedEval = {
    timestamp: new Date().toISOString(),
    taskId: task.id,
    
    // Overall status
    overallPassed: data.functionalEval.passed && 
                   data.qualityEval.passed && 
                   data.safetyEval.passed && 
                   data.performanceEval.passed,
    
    // Individual eval results
    functional: {
      passed: data.functionalEval.passed,
      errors: data.functionalEval.errors
    },
    
    quality: {
      passed: data.qualityEval.passed,
      score: data.qualityEval.overallScore,
      weaknesses: data.qualityEval.weaknesses
    },
    
    safety: {
      passed: data.safetyEval.passed,
      piiDetected: data.safetyEval.piiDetected,
      harmfulContent: data.safetyEval.harmfulContent
    },
    
    performance: {
      passed: data.performanceEval.passed,
      executionTime: data.performanceEval.executionTime.seconds,
      cost: data.performanceEval.cost.estimated,
      tokens: data.performanceEval.tokenUsage.total
    }
  };
  
  // Add to task metadata for querying
  data.evaluationResults = consolidatedEval;
  
  // Tag task with eval status for filtering
  const currentTags = task.tags() || [];
  const evalTag = consolidatedEval.overallPassed ? 'eval:passed' : 'eval:failed';
  task.tags([...currentTags, evalTag, 'evaluated']);
  
  data.evalResultsStored = true;
  
  console.log(`Eval results stored - Overall: ${consolidatedEval.overallPassed ? 'PASSED' : 'FAILED'}`);
};
```

#### Visualization & Reporting

Generate reports and dashboards for stakeholders:

```javascript
// Weekly Evaluation Report Generation
export const condition = {
  reportGeneration: {
    trigger: 'weekly',
    week: String
  },
  agentMetrics: Object,
  reportGenerated: null
};

export const content = async () => {
  console.log(`Generating weekly evaluation report for week: ${data.reportGeneration.week}...`);
  
  const metrics = data.agentMetrics.metrics;
  
  // Create comprehensive report
  const report = {
    reportType: 'weekly_agent_evaluation',
    week: data.reportGeneration.week,
    generatedAt: new Date().toISOString(),
    
    executiveSummary: {
      overallHealth: metrics.quality.passRate >= 95 ? 'Excellent' : 
                     metrics.quality.passRate >= 90 ? 'Good' : 
                     metrics.quality.passRate >= 85 ? 'Fair' : 'Poor',
      keyHighlights: [
        `${metrics.quality.passRate}% pass rate (${metrics.improvements.weekOverWeekQualityChange > 0 ? '+' : ''}${metrics.improvements.weekOverWeekQualityChange}% vs last week)`,
        `Average quality score: ${metrics.quality.avgQualityScore}/10`,
        `${metrics.volume.totalTasks} tasks processed, ${metrics.volume.tasksEvaluated} evaluated`,
        `Cost efficiency: ${metrics.performance.avgCost} per task (${metrics.improvements.weekOverWeekCostChange}% vs last week)`
      ],
      actionItems: []
    },
    
    qualityMetrics: {
      passRate: metrics.quality.passRate,
      qualityScore: metrics.quality.avgQualityScore,
      humanAgreement: metrics.quality.humanAgreementRate,
      trend: metrics.improvements.weekOverWeekQualityChange
    },
    
    performanceMetrics: {
      avgExecutionTime: metrics.performance.avgExecutionTime,
      avgCost: metrics.performance.avgCost,
      totalCost: metrics.performance.totalCost,
      tokenEfficiency: metrics.performance.tokenEfficiency
    },
    
    safetyMetrics: {
      violations: metrics.safety.safetyViolations,
      piiDetectionRate: metrics.safety.piiDetectionRate,
      promptInjections: metrics.safety.promptInjectionAttempts
    },
    
    errorAnalysis: {
      totalErrors: metrics.errors.totalErrors,
      errorRate: metrics.errors.errorRate,
      topErrors: Object.entries(metrics.errors.commonErrorTypes)
        .sort((a, b) => b[1] - a[1])
        .slice(0, 5)
        .map(([error, count]) => ({ error, count, percentage: (count / metrics.errors.totalErrors * 100).toFixed(1) }))
    }
  };
  
  // Add action items based on metrics
  if (metrics.quality.passRate < 95) {
    report.executiveSummary.actionItems.push('Review and optimize agent prompts to improve pass rate');
  }
  if (metrics.safety.safetyViolations > 0) {
    report.executiveSummary.actionItems.push(`Investigate ${metrics.safety.safetyViolations} safety violations`);
  }
  if (metrics.performance.avgCost > 0.10) {
    report.executiveSummary.actionItems.push('Optimize token usage to reduce cost per task');
  }
  
  data.evaluationReport = report;
  
  // Send report to stakeholders
  await connectors.email.send({
    to: 'ai-team@company.com,management@company.com',
    subject: `AI Agent Evaluation Report - Week ${data.reportGeneration.week}`,
    body: generateReportEmail(report)
  });
  
  data.reportGenerated = true;
  
  console.log(`Weekly report generated and sent - Overall health: ${report.executiveSummary.overallHealth}`);
};

// Helper function to generate email
const generateReportEmail = (report) => {
  return `
# AI Agent Evaluation Report
**Week:** ${report.week}
**Generated:** ${new Date(report.generatedAt).toLocaleString()}

## Executive Summary
**Overall Health:** ${report.executiveSummary.overallHealth}

**Key Highlights:**
${report.executiveSummary.keyHighlights.map(h => `- ${h}`).join('\n')}

**Action Items:**
${report.executiveSummary.actionItems.length > 0 ? report.executiveSummary.actionItems.map(a => `- ${a}`).join('\n') : '- None - system performing well'}

## Quality Metrics
- **Pass Rate:** ${report.qualityMetrics.passRate}% (trend: ${report.qualityMetrics.trend > 0 ? '+' : ''}${report.qualityMetrics.trend}%)
- **Quality Score:** ${report.qualityMetrics.qualityScore}/10
- **Human Agreement:** ${report.qualityMetrics.humanAgreement}%

## Performance Metrics
- **Avg Execution Time:** ${report.performanceMetrics.avgExecutionTime}s
- **Avg Cost:** ${report.performanceMetrics.avgCost}
- **Total Cost:** ${report.performanceMetrics.totalCost}
- **Token Efficiency:** ${report.performanceMetrics.tokenEfficiency} tokens/task

## Safety Metrics
- **Safety Violations:** ${report.safetyMetrics.violations}
- **PII Detection Rate:** ${report.safetyMetrics.piiDetectionRate}%
- **Prompt Injection Attempts:** ${report.safetyMetrics.promptInjections}

## Error Analysis
**Total Errors:** ${report.errorAnalysis.totalErrors} (${report.errorAnalysis.errorRate}% error rate)

**Top 5 Error Types:**
${report.errorAnalysis.topErrors.map(e => `- ${e.error}: ${e.count} (${e.percentage}%)`).join('\n')}

---
View full dashboard: https://monitoring.company.com/agent-evals
  `;
};
```

***

### Continuous Improvement Loop

#### Using Eval Results for Agent Optimization

```javascript
// Improvement Opportunity Identification
export const condition = {
  evaluationReport: Object,
  improvementAnalysis: null
};

export const content = async () => {
  console.log('Analyzing evaluation data for improvement opportunities...');
  
  const report = data.evaluationReport;
  const errorAnalysis = report.errorAnalysis;
  
  // Use LLM to analyze patterns and suggest improvements
  const improvementAnalysis = await connectors.openai.chat({
    model: 'gpt-4',
    messages: [
      {
        role: 'system',
        content: `You are an AI agent optimization expert. Analyze evaluation data and provide specific, actionable improvement recommendations.

Focus on:
1. Prompt engineering improvements
2. Model selection optimization
3. Error handling enhancements
4. Performance optimizations
5. Safety guardrail additions

Return structured JSON with specific recommendations.`
      },
      {
        role: 'user',
        content: `Evaluation Summary:
- Pass Rate: ${report.qualityMetrics.passRate}%
- Quality Score: ${report.qualityMetrics.qualityScore}/10
- Avg Cost: ${report.performanceMetrics.avgCost}
- Error Rate: ${report.errorAnalysis.errorRate}%

Top Errors:
${report.errorAnalysis.topErrors.map(e => `- ${e.error}: ${e.count} occurrences`).join('\n')}

Safety Issues:
- Violations: ${report.safetyMetrics.violations}
- PII Detections: ${report.safetyMetrics.piiDetectionRate}%

Provide specific recommendations to improve agent performance.`
      }
    ]
  });
  
  const recommendations = JSON.parse(improvementAnalysis.choices[0].message.content);
  
  data.improvementAnalysis = {
    recommendations: recommendations,
    prioritizedActions: recommendations.prioritizedActions || [],
    estimatedImpact: recommendations.estimatedImpact || {},
    analyzedAt: new Date().toISOString()
  };
  
  console.log(`Improvement analysis complete - ${recommendations.prioritizedActions.length} recommendations identified`);
};

// Create Improvement Experiments
export const condition = {
  improvementAnalysis: Object,
  experimentsCreated: null
};

export const content = async () => {
  console.log('Creating A/B testing experiments for improvements...');
  
  const recommendations = data.improvementAnalysis.recommendations;
  
  // Select top 3 recommendations for testing
  const topRecommendations = data.improvementAnalysis.prioritizedActions.slice(0, 3);
  
  const experiments = topRecommendations.map((recommendation, index) => ({
    experimentId: `exp_${Date.now()}_${index}`,
    name: recommendation.name,
    hypothesis: recommendation.hypothesis,
    changes: recommendation.changes,
    
    // A/B test configuration
    control: {
      version: 'current',
      allocation: 50 // 50% of traffic
    },
    treatment: {
      version: recommendation.version,
      changes: recommendation.changes,
      allocation: 50 // 50% of traffic
    },
    
    // Success criteria
    successMetrics: {
      primaryMetric: recommendation.primaryMetric,
      targetImprovement: recommendation.targetImprovement,
      minimumSampleSize: 100
    },
    
    status: 'pending',
    createdAt: new Date().toISOString()
  }));
  
  data.experiments = experiments;
  data.experimentsCreated = true;
  
  console.log(`Created ${experiments.length} improvement experiments`);
};
```

#### Version Control for Agents

Track changes and enable rollback:

```javascript
// Agent Version Management
export const condition = {
  agentUpdate: {
    trigger: true,
    changes: Object
  },
  versionCreated: null
};

export const content = async () => {
  console.log('Creating new agent version...');
  
  const changes = data.agentUpdate.changes;
  
  // Create version record
  const newVersion = {
    version: `v${data.agent.currentVersion + 1}`,
    previousVersion: `v${data.agent.currentVersion}`,
    changes: changes,
    changeType: changes.type, // 'prompt', 'model', 'parameters', etc.
    
    // Version metadata
    createdAt: new Date().toISOString(),
    createdBy: data.agentUpdate.updatedBy,
    reason: changes.reason,
    
    // Configuration snapshot
    configuration: {
      model: changes.newModel || data.agent.configuration.model,
      systemPrompt: changes.newPrompt || data.agent.configuration.systemPrompt,
      temperature: changes.newTemperature || data.agent.configuration.temperature,
      maxTokens: changes.newMaxTokens || data.agent.configuration.maxTokens
    },
    
    // Evaluation baseline
    baselineMetrics: {
      passRate: data.agentMetrics?.metrics.quality.passRate,
      qualityScore: data.agentMetrics?.metrics.quality.avgQualityScore,
      avgCost: data.agentMetrics?.metrics.performance.avgCost
    }
  };
  
  // Store version history
  data.agent.versionHistory = data.agent.versionHistory || [];
  data.agent.versionHistory.push(newVersion);
  
  // Update current version
  data.agent.currentVersion = data.agent.currentVersion + 1;
  data.agent.configuration = newVersion.configuration;
  
  data.versionCreated = newVersion;
  
  console.log(`Agent version ${newVersion.version} created - Changes: ${changes.type}`);
};

// Version Performance Comparison
export const condition = {
  versionComparison: {
    trigger: true,
    versionA: String,
    versionB: String
  },
  comparisonComplete: null
};

export const content = async () => {
  console.log(`Comparing agent versions: ${data.versionComparison.versionA} vs ${data.versionComparison.versionB}...`);
  
  const versionA = data.agent.versionHistory.find(v => v.version === data.versionComparison.versionA);
  const versionB = data.agent.versionHistory.find(v => v.version === data.versionComparison.versionB);
  
  // In production, query actual performance data for each version
  // This example shows the comparison structure
  const comparison = {
    versions: {
      control: versionA.version,
      treatment: versionB.version
    },
    
    metrics: {
      qualityScore: {
        control: versionA.baselineMetrics.qualityScore,
        treatment: versionB.baselineMetrics.qualityScore,
        improvement: ((versionB.baselineMetrics.qualityScore - versionA.baselineMetrics.qualityScore) / versionA.baselineMetrics.qualityScore * 100).toFixed(2)
      },
      passRate: {
        control: versionA.baselineMetrics.passRate,
        treatment: versionB.baselineMetrics.passRate,
        improvement: (versionB.baselineMetrics.passRate - versionA.baselineMetrics.passRate).toFixed(2)
      },
      avgCost: {
        control: versionA.baselineMetrics.avgCost,
        treatment: versionB.baselineMetrics.avgCost,
        improvement: ((versionA.baselineMetrics.avgCost - versionB.baselineMetrics.avgCost) / versionA.baselineMetrics.avgCost * 100).toFixed(2)
      }
    },
    
    // Statistical significance (placeholder - in production, calculate properly)
    statisticalSignificance: {
      qualityScore: true,
      passRate: true,
      avgCost: false
    },
    
    recommendation: null
  };
  
  // Determine recommendation
  const qualityImproved = parseFloat(comparison.metrics.qualityScore.improvement) > 0;
  const costReduced = parseFloat(comparison.metrics.avgCost.improvement) > 0;
  
  if (qualityImproved && costReduced) {
    comparison.recommendation = `Deploy ${versionB.version} - improves quality and reduces cost`;
  } else if (qualityImproved && !costReduced) {
    comparison.recommendation = `Consider deploying ${versionB.version} - quality improved but cost increased`;
  } else if (!qualityImproved && costReduced) {
    comparison.recommendation = `Not recommended - cost reduced but quality degraded`;
  } else {
    comparison.recommendation = `Keep ${versionA.version} - no significant improvements`;
  }
  
  data.versionComparisonResults = comparison;
  data.comparisonComplete = true;
  
  console.log(`Version comparison complete - Recommendation: ${comparison.recommendation}`);
};
```

***

### Common Eval Patterns

#### Pattern: Factual Accuracy Check

Validate agent claims against source data:

```javascript
// Factual Accuracy Evaluation
export const condition = {
  agentOutput: {
    researchSummary: String,
    sources: Array
  },
  factualAccuracyEval: null
};

export const content = async () => {
  console.log('Evaluating factual accuracy of agent output...');
  
  const summary = data.agentOutput.researchSummary;
  const sources = data.agentOutput.sources;
  
  // Extract claims from summary
  const claimExtraction = await connectors.openai.chat({
    model: 'gpt-4',
    messages: [
      {
        role: 'system',
        content: 'Extract specific factual claims from this text. Return JSON array of claims.'
      },
      {
        role: 'user',
        content: summary
      }
    ]
  });
  
  const claims = JSON.parse(claimExtraction.choices[0].message.content);
  
  // Verify each claim against sources
  const verifications = [];
  
  for (const claim of claims.claims) {
    const verification = await connectors.openai.chat({
      model: 'gpt-4',
      messages: [
        {
          role: 'system',
          content: 'Verify if this claim is supported by the provided sources. Return JSON: {supported: boolean, confidence: 0-100, evidence: string}'
        },
        {
          role: 'user',
          content: `Claim: ${claim}
          
Sources:
${sources.map(s => `- ${s.title}: ${s.content}`).join('\n\n')}

Is this claim supported by the sources?`
        }
      ]
    });
    
    const result = JSON.parse(verification.choices[0].message.content);
    verifications.push({
      claim: claim,
      ...result
    });
  }
  
  // Calculate overall accuracy
  const supportedClaims = verifications.filter(v => v.supported).length;
  const accuracyRate = (supportedClaims / verifications.length * 100).toFixed(1);
  const accuracyThreshold = 95; // 95% accuracy required
  
  data.factualAccuracyEval = {
    passed: parseFloat(accuracyRate) >= accuracyThreshold,
    totalClaims: verifications.length,
    supportedClaims: supportedClaims,
    accuracyRate: parseFloat(accuracyRate),
    threshold: accuracyThreshold,
    verifications: verifications,
    evaluatedAt: new Date().toISOString()
  };
  
  console.log(`Factual accuracy eval: ${data.factualAccuracyEval.passed ? 'PASSED' : 'FAILED'} - ${accuracyRate}% accurate`);
};
```

#### Pattern: Format Compliance

Ensure outputs match required schema:

```javascript
// Format Compliance Evaluation
export const condition = {
  agentOutput: {
    structuredData: Object
  },
  formatComplianceEval: null
};

export const content = async () => {
  console.log('Evaluating format compliance...');
  
  const output = data.agentOutput.structuredData;
  
  // Define expected schema
  const requiredSchema = {
    customer: {
      name: 'string',
      email: 'string',
      phone: 'string',
      tier: 'string' // must be: 'free', 'pro', 'enterprise'
    },
    classification: {
      category: 'string',
      urgency: 'string', // must be: 'low', 'medium', 'high', 'critical'
      confidence: 'number' // must be 0-100
    },
    actions: 'array' // must contain at least 1 action
  };
  
  const validationResults = {
    errors: [],
    warnings: []
  };
  
  // Validate structure
  const validateField = (path, expectedType, value) => {
    if (value === undefined || value === null) {
      validationResults.errors.push(`Missing required field: ${path}`);
      return false;
    }
    
    const actualType = Array.isArray(value) ? 'array' : typeof value;
    if (actualType !== expectedType) {
      validationResults.errors.push(`Type mismatch at ${path}: expected ${expectedType}, got ${actualType}`);
      return false;
    }
    
    return true;
  };
  
  // Validate customer fields
  validateField('customer.name', 'string', output.customer?.name);
  validateField('customer.email', 'string', output.customer?.email);
  validateField('customer.phone', 'string', output.customer?.phone);
  validateField('customer.tier', 'string', output.customer?.tier);
  
  // Validate customer.tier enum
  if (output.customer?.tier && !['free', 'pro', 'enterprise'].includes(output.customer.tier)) {
    validationResults.errors.push(`Invalid customer.tier: ${output.customer.tier} (must be: free, pro, or enterprise)`);
  }
  
  // Validate classification fields
  validateField('classification.category', 'string', output.classification?.category);
  validateField('classification.urgency', 'string', output.classification?.urgency);
  validateField('classification.confidence', 'number', output.classification?.confidence);
  
  // Validate urgency enum
  if (output.classification?.urgency && !['low', 'medium', 'high', 'critical'].includes(output.classification.urgency)) {
    validationResults.errors.push(`Invalid classification.urgency: ${output.classification.urgency}`);
  }
  
  // Validate confidence range
  if (typeof output.classification?.confidence === 'number' && 
      (output.classification.confidence < 0 || output.classification.confidence > 100)) {
    validationResults.errors.push(`confidence must be 0-100, got: ${output.classification.confidence}`);
  }
  
  // Validate actions array
  validateField('actions', 'array', output.actions);
  if (Array.isArray(output.actions) && output.actions.length === 0) {
    validationResults.errors.push('actions array must contain at least 1 action');
  }
  
  // Email format validation
  if (output.customer?.email && !/^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(output.customer.email)) {
    validationResults.warnings.push(`Email format may be invalid: ${output.customer.email}`);
  }
  
  data.formatComplianceEval = {
    passed: validationResults.errors.length === 0,
    errors: validationResults.errors,
    warnings: validationResults.warnings,
    schema: requiredSchema,
    evaluatedAt: new Date().toISOString()
  };
  
  console.log(`Format compliance eval: ${data.formatComplianceEval.passed ? 'PASSED' : 'FAILED'} - ${validationResults.errors.length} errors, ${validationResults.warnings.length} warnings`);
};
```

#### Pattern: Cost Optimization

Monitor and optimize token usage:

```javascript
// Cost Optimization Analysis
export const condition = {
  performanceEval: {
    passed: true,
    cost: Object,
    tokenUsage: Object
  },
  costOptimizationAnalysis: null
};

export const content = async () => {
  console.log('Analyzing cost optimization opportunities...');
  
  const cost = data.performanceEval.cost.estimated;
  const tokens = data.performanceEval.tokenUsage;
  const executionTime = data.performanceEval.executionTime.seconds;
  
  // Identify optimization opportunities
  const opportunities = [];
  
  // 1. High token usage
  if (tokens.total > 5000) {
    opportunities.push({
      type: 'token_reduction',
      issue: 'High token usage detected',
      currentUsage: tokens.total,
      targetUsage: 3000,
      potentialSavings: ((tokens.total - 3000) / 1000 * 0.03).toFixed(4),
      recommendations: [
        'Reduce system prompt length',
        'Implement prompt caching',
        'Use shorter examples in few-shot learning'
      ]
    });
  }
  
  // 2. Model selection
  if (data.agentExecution.model === 'gpt-4' && data.qualityEval?.overallScore < 8) {
    opportunities.push({
      type: 'model_downgrade',
      issue: 'Using expensive model without proportional quality benefit',
      currentModel: 'gpt-4',
      recommendedModel: 'gpt-3.5-turbo',
      potentialSavings: (cost * 0.90).toFixed(4), // 90% cost reduction
      recommendations: [
        'Test gpt-3.5-turbo for this use case',
        'A/B test model performance vs cost'
      ]
    });
  }
  
  // 3. Unnecessary API calls
  if (data.agentExecution.apiCalls > 3) {
    opportunities.push({
      type: 'reduce_api_calls',
      issue: 'Multiple API calls could be consolidated',
      currentCalls: data.agentExecution.apiCalls,
      targetCalls: 2,
      potentialSavings: (cost / data.agentExecution.apiCalls * (data.agentExecution.apiCalls - 2)).toFixed(4),
      recommendations: [
        'Consolidate prompts into single call',
        'Use batch processing where possible'
      ]
    });
  }
  
  // Calculate total potential savings
  const totalPotentialSavings = opportunities.reduce((sum, opp) => 
    sum + parseFloat(opp.potentialSavings), 0
  );
  
  data.costOptimizationAnalysis = {
    currentCost: cost,
    currentTokens: tokens.total,
    opportunities: opportunities,
    totalPotentialSavings: totalPotentialSavings.toFixed(4),
    savingsPercentage: (totalPotentialSavings / cost * 100).toFixed(1),
    analyzedAt: new Date().toISOString()
  };
  
  console.log(`Cost optimization: ${opportunities.length} opportunities identified - Potential savings: ${totalPotentialSavings.toFixed(4)} (${data.costOptimizationAnalysis.savingsPercentage}%)`);
};
```

#### Pattern: Safety Guardrails

Implement comprehensive safety checks:

```javascript
// Comprehensive Safety Guardrails
export const condition = {
  agentOutput: {
    response: String
  },
  safetyGuardrails: null
};

export const content = async () => {
  console.log('Running comprehensive safety guardrails...');
  
  const response = data.agentOutput.response;
  const safetyChecks = {
    passed: true,
    violations: []
  };
  
  // 1. PII Detection (enhanced patterns)
  const piiDetection = {
    email: /[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/g,
    phone: /(\+\d{1,3}[\s-])?\(?\d{3}\)?[\s.-]?\d{3}[\s.-]?\d{4}/g,
    ssn: /\d{3}-\d{2}-\d{4}/g,
    creditCard: /\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}/g,
    ipAddress: /\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b/g,
    apiKey: /[a-zA-Z0-9]{20,}/g // Generic API key pattern
  };
  
  for (const [type, pattern] of Object.entries(piiDetection)) {
    const matches = response.match(pattern);
    if (matches) {
      safetyChecks.passed = false;
      safetyChecks.violations.push({
        type: 'pii_leakage',
        category: type,
        count: matches.length,
        severity: 'critical'
      });
    }
  }
  
  // 2. Prompt Injection Detection
  const injectionPatterns = [
    /ignore (previous|above|all) instructions/i,
    /system prompt/i,
    /you are now/i,
    /forget everything/i,
    /new instruction:/i
  ];
  
  for (const pattern of injectionPatterns) {
    if (
```
